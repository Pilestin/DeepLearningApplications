import streamlit as st
import requests
from bs4 import BeautifulSoup
from transformers import pipeline
import os
from datetime import datetime
from urllib.parse import urlparse
import hashlib

from static.css import css_string
from news_scrapping.finans import finans_news
from news_scrapping.teknoloji import teknoloji_news


# Sayfa konfigÃ¼rasyonu
st.set_page_config(
    page_title="Haber Ã–zetleyici",
    page_icon="ðŸ“°",
    layout="wide",
    initial_sidebar_state="expanded"
)


# CSS ekleme
st.markdown(css_string, unsafe_allow_html=True)

# Veri depolama iÃ§in dizin oluÅŸturma
DATA_DIR = "news_data"
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

# Oturum durumu yÃ¶netimi
if 'news_data' not in st.session_state:
    st.session_state.news_data = []
if 'summarized_news' not in st.session_state:
    st.session_state.summarized_news = {}
if 'all_summarized' not in st.session_state:
    st.session_state.all_summarized = False
if 'selected_category' not in st.session_state:
    st.session_state.selected_category = "Teknoloji"

# Kategori tanÄ±mlarÄ±
CATEGORIES = {
    "Teknoloji": {
        "url": "https://shiftdelete.net",
        "selector": "custom"  # Ã–zel iÅŸleyici iÃ§in iÅŸaret
    },
    "GÃ¼ndem": {
        "url": "https://www.hurriyet.com.tr/gundem/",
        "selector": "div.container div.news-card"
    },
    "Finans": {
        "url": "https://www.doviz.com",
        "selector": "custom"  # Ã–zel iÅŸleyici iÃ§in iÅŸaret
    }
}

# Model yÃ¼kleme (bir defa cache'lenir)
@st.cache_resource
def load_summarizer():
    summarizer = pipeline(
        "summarization", 
        model="ozcangundes/mt5-small-turkish-summarization",
        device=0 if "cuda" in str(st.__version__) else -1
    )
    return summarizer

# Haber metni Ã§ekme fonksiyonu
def fetch_news_content(url):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            if "hurriyet.com.tr" in url:
                article_body = soup.select_one("div.news-content")
                if article_body:
                    paragraphs = article_body.find_all('p')
                    content = ' '.join([p.text for p in paragraphs])
                    return content
            else:
                # Paragraph etiketlerindeki metinleri al
                paragraphs = soup.find_all('p')
                content = ' '.join([p.text for p in paragraphs if len(p.text) > 100])
                return content
        return "Ä°Ã§erik Ã§ekilemedi."
    except Exception as e:
        return f"Hata: {str(e)}"

# Haber listesi Ã§ekme fonksiyonu
def fetch_news_list(category):

    news_list = []
    try:
        cat_info = CATEGORIES[category]
        # Teknoloji kategorisi iÃ§in Ã¶zel iÅŸleme
        if category == "Teknoloji":
            return [
                {
                    "id": hashlib.md5(news["link"].encode()).hexdigest(),
                    "title": news["title"],
                    "url": news["link"],
                    "image": news["image"],
                    "summary": news["summary"],
                    "source": "ShiftDelete.Net",
                    "date": news["time"],
                    "category": category,
                    "content": news["content"],
                    "ai_summary": None
                }
                for news in teknoloji_news(cat_info["url"], limit=10)
            ]
        
        # Finans kategorisi iÃ§in Ã¶zel iÅŸleme
        if category == "Finans":
            return [
                {
                    "id": hashlib.md5(news["link"].encode()).hexdigest(),
                    "title": news["title"],
                    "url": news["link"],
                    "image": news["image"],
                    "summary": news["summary"],
                    "source": "Doviz.com",
                    "date": news["time"],
                    "category": category,
                    "content": news["content"],
                    "ai_summary": None
                }
                for news in finans_news(cat_info["url"], limit=10)
            ]
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        st.write(f"Veri Ã§ekiliyor: {cat_info['url']}")
        response = requests.get(cat_info["url"], headers=headers, timeout=10)
        if response.status_code != 200:
            st.error(f"Veri Ã§ekilirken hata oluÅŸtu: {response.status_code}")
        else:
            st.success(f"STATUS[{response.status_code}]")
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                news_items = soup.select(cat_info["selector"])
                
                for item in news_items[:10]:  
                    st.write(f"Ä°ÅŸleniyor: {item}")
                    try:
                        title_element = item.select_one("div.news-title a, h3.news-title a")
                        if not title_element:
                            continue
                            
                        title = title_element.text.strip()
                        url = title_element['href']
                        
                        # EÄŸer URL tam deÄŸilse (baÄŸÄ±l yol), tam URL'ye dÃ¶nÃ¼ÅŸtÃ¼r
                        if not url.startswith('http'):
                            parsed_base = urlparse(cat_info["url"])
                            base_url = f"{parsed_base.scheme}://{parsed_base.netloc}"
                            url = base_url + url
                        
                        # Resim bulma
                        img_element = item.select_one("img")
                        img_url = img_element['src'] if img_element and 'src' in img_element.attrs else ""
                        
                        # EÄŸer resim URL'si tam deÄŸilse (baÄŸÄ±l yol), tam URL'ye dÃ¶nÃ¼ÅŸtÃ¼r
                        if img_url and not img_url.startswith('http'):
                            parsed_base = urlparse(cat_info["url"])
                            base_url = f"{parsed_base.scheme}://{parsed_base.netloc}"
                            img_url = base_url + img_url
                        
                        # Ã–zet bulma
                        summary_element = item.select_one("div.news-summary, div.news-description")
                        summary = summary_element.text.strip() if summary_element else ""
                        
                        # Kaynak ve tarih tanÄ±mlama
                        source = "HÃ¼rriyet"
                        date = datetime.now().strftime("%d.%m.%Y")
                        
                        # Haberi benzersiz tanÄ±mlamak iÃ§in hash oluÅŸturma
                        news_id = hashlib.md5(url.encode()).hexdigest()
                        
                        news_list.append({
                            "id": news_id,
                            "title": title,
                            "url": url,
                            "image": img_url,
                            "summary": summary,
                            "source": source,
                            "date": date,
                            "category": category,
                            "content": None,  # Ä°Ã§erik sonradan Ã§ekilecek
                            "ai_summary": None  # AI Ã¶zeti sonradan oluÅŸturulacak
                        })
                    except Exception as e:
                        continue
        
        return news_list
    except Exception as e:
        st.error(f"Haberler Ã§ekilirken hata oluÅŸtu: {str(e)}")
        return []

# Haber Ã¶zetleme fonksiyonu
def summarize_news(content, max_length=300, min_length=80):
    """Haber iÃ§eriÄŸini Ã¶zetler."""
    
    if not content or len(content.strip()) < 100:
        return "Ã–zetlenecek yeterli iÃ§erik bulunamadÄ±."
    
    try:
        # Ä°Ã§eriÄŸi temizle
        cleaned_content = clean_content(content)
        
        # Ã‡ok kÄ±sa iÃ§erik kontrolÃ¼
        if len(cleaned_content.split()) < 30:
            return "Ä°Ã§erik Ã§ok kÄ±sa, Ã¶zetleme yapÄ±lamadÄ±."
        
        # Model yÃ¼kle
        summarizer = load_summarizer()
        
        # Ä°Ã§erik uzunluÄŸuna gÃ¶re iÅŸlem yap
        if len(cleaned_content) > 1024:
            # Uzun iÃ§erikleri parÃ§alara bÃ¶l
            parts = split_content(cleaned_content, max_length=900)
            summaries = []
            
            for part in parts:
                if len(part.split()) > 10:  # Ã‡ok kÄ±sa parÃ§alarÄ± atla
                    try:
                        part_summary = summarizer(
                            part,
                            max_length=min(150, max_length // len(parts)),
                            min_length=min(40, min_length),
                            num_beams=4,
                            no_repeat_ngram_size=2,
                            early_stopping=True,
                            do_sample=False,  # Deterministik sonuÃ§ iÃ§in
                            length_penalty=1.0
                        )[0]['summary_text']
                        summaries.append(part_summary)
                    except Exception as e:
                        continue
            
            if summaries:
                # ParÃ§a Ã¶zetlerini birleÅŸtir
                combined_summary = " ".join(summaries)
                
                # Final Ã¶zet (eÄŸer Ã§ok uzunsa)
                if len(combined_summary.split()) > max_length // 4:
                    final_summary = summarizer(
                        combined_summary,
                        max_length=max_length,
                        min_length=min_length,
                        num_beams=4,
                        no_repeat_ngram_size=2,
                        early_stopping=True,
                        do_sample=False,
                        length_penalty=1.0
                    )[0]['summary_text']
                    return final_summary
                else:
                    return combined_summary
            else:
                return "Ã–zetleme iÅŸlemi baÅŸarÄ±sÄ±z oldu."
        
        else:
            # Normal uzunluktaki iÃ§erikler iÃ§in
            summary = summarizer(
                cleaned_content,
                max_length=max_length,
                min_length=min_length,
                num_beams=4,
                no_repeat_ngram_size=3,  # TekrarlarÄ± azalt
                early_stopping=True,
                do_sample=False,
                length_penalty=1.2,  # Daha uzun Ã¶zetler iÃ§in
                repetition_penalty=1.2  # TekrarlarÄ± penalize et
            )[0]['summary_text']
            
            return summary
            
    except Exception as e:
        return f"Ã–zetleme sÄ±rasÄ±nda hata: {str(e)}"

def clean_content(content: str) -> str:
    """Ä°Ã§eriÄŸi temizler ve dÃ¼zenler."""
    import re
    
    if not content:
        return ""
    
    # HTML etiketlerini kaldÄ±r
    content = re.sub(r'<[^>]+>', '', content)
    
    # Ã‡oklu boÅŸluklarÄ± tek boÅŸluÄŸa Ã§evir
    content = re.sub(r'\s+', ' ', content)
    
    # URL'leri kaldÄ±r
    content = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', content)
    
    # Email adreslerini kaldÄ±r
    content = re.sub(r'\S*@\S*\s?', '', content)
    
    # Gereksiz karakterleri temizle ama TÃ¼rkÃ§e karakterleri koru
    content = re.sub(r'[^\w\sÃ‡ÄžÄ±Ä°Ã–ÅžÃœÃ§ÄŸÄ±Ã¶ÅŸÃ¼\.,!?;\-:]', '', content)
    
    # Ã‡oklu noktalama iÅŸaretlerini tekli yap
    content = re.sub(r'\.{2,}', '.', content)
    content = re.sub(r'\!{2,}', '!', content)
    content = re.sub(r'\?{2,}', '?', content)
    
    # Gereksiz kelime tekrarlarÄ±nÄ± azalt
    words = content.split()
    cleaned_words = []
    prev_word = ""
    
    for word in words:
        if word.lower() != prev_word.lower() or len(cleaned_words) == 0:
            cleaned_words.append(word)
        prev_word = word
    
    return ' '.join(cleaned_words).strip()

def split_content(content: str, max_length: int = 900) -> list:
    """Uzun iÃ§eriÄŸi anlamlÄ± parÃ§alara bÃ¶ler."""
    
    # Ã–nce paragraflara bÃ¶l
    paragraphs = [p.strip() for p in content.split('\n') if p.strip()]
    
    if not paragraphs:
        # Paragraf yoksa cÃ¼mlelere bÃ¶l
        sentences = [s.strip() + '.' for s in content.split('.') if s.strip()]
    else:
        sentences = []
        for para in paragraphs:
            sentences.extend([s.strip() + '.' for s in para.split('.') if s.strip()])
    
    parts = []
    current_part = []
    current_length = 0
    
    for sentence in sentences:
        sentence_length = len(sentence.split())
        
        if current_length + sentence_length > max_length // 4:  # Word count based
            if current_part:
                parts.append(' '.join(current_part))
            current_part = [sentence]
            current_length = sentence_length
        else:
            current_part.append(sentence)
            current_length += sentence_length
    
    if current_part:
        parts.append(' '.join(current_part))
    
    return parts

# Haberi Ã¶zetleme ve session state'e kaydetme
def summarize_and_save(news_id):
    for i, news in enumerate(st.session_state.news_data):
        if news["id"] == news_id:
            # Ä°Ã§erik henÃ¼z Ã§ekilmemiÅŸse Ã§ek
            if not news["content"]:
                with st.spinner(f"'{news['title']}' haberi Ã§ekiliyor..."):
                    content = fetch_news_content(news["url"])
                    
                    # Ä°Ã§erik Ã§ekilemediÄŸi durumda Ã¶zeti kullanma (Ã¶zetleme kalitesini dÃ¼ÅŸÃ¼rÃ¼r)
                    if len(content.strip()) < 100 and news["summary"]:
                        # Ã–zeti kullan ama kullanÄ±cÄ±yÄ± bilgilendir
                        st.warning("Haber iÃ§eriÄŸi Ã§ekilemedi, mevcut Ã¶zet kullanÄ±lacak.")
                        content = news["summary"]
                    
                    news["content"] = content
                    st.session_state.news_data[i] = news
            
            # Ä°Ã§erik varsa Ã¶zetle
            if news["content"] and len(news["content"].strip()) > 50:
                with st.spinner(f"'{news['title']}' haberi Ã¶zetleniyor..."):
                    summary = summarize_news(
                        news["content"],
                        max_length=300,  # Daha uzun Ã¶zetler
                        min_length=80    # Minimum uzunluk
                    )
                    
                    # Ã–zet kalitesi kontrolÃ¼
                    if (summary and 
                        not summary.startswith("Hata:") and 
                        len(summary.split()) > 10 and
                        summary != news.get("summary", "")):  # Orijinal Ã¶zetle aynÄ± deÄŸilse
                        
                        news["ai_summary"] = summary
                        st.session_state.summarized_news[news_id] = True
                        st.success("Ã–zet baÅŸarÄ±yla oluÅŸturuldu!")
                    else:
                        st.error("Ã–zet oluÅŸturulamadÄ± veya yetersiz kalitede.")
                        news["ai_summary"] = "Ã–zet oluÅŸturulamadÄ±."
                    
                    st.session_state.news_data[i] = news
            else:
                st.error("Ã–zetlenecek yeterli iÃ§erik bulunamadÄ±.")
            break
    
    st.rerun()

# TÃ¼m haberleri Ã¶zetleme
def summarize_all_news():
    with st.spinner("TÃ¼m haberler Ã¶zetleniyor..."):
        progress_bar = st.progress(0)
        total_news = len(st.session_state.news_data)
        
        for i, news in enumerate(st.session_state.news_data):
            # Ä°Ã§erik henÃ¼z Ã§ekilmemiÅŸse Ã§ek
            if not news["content"]:
                news["content"] = fetch_news_content(news["url"])
            
            # Ä°Ã§erik varsa Ã¶zetle
            if news["content"]:
                summary = summarize_news(news["content"])
                news["ai_summary"] = summary
                st.session_state.summarized_news[news["id"]] = True
            
            # Ä°lerleme gÃ¼ncellemesi
            progress_bar.progress((i + 1) / total_news)
        
        st.session_state.all_summarized = True
    
    st.rerun()

# Kategori deÄŸiÅŸtirme fonksiyonu
def change_category(category):
    if st.session_state.selected_category != category:
        st.session_state.selected_category = category
        st.session_state.news_data = []
        st.session_state.summarized_news = {}
        st.session_state.all_summarized = False
        
        with st.spinner(f"{category} haberleri yÃ¼kleniyor..."):
            st.session_state.news_data = fetch_news_list(category)

    st.rerun()

# Ana uygulama fonksiyo
def main():

    st.markdown("<div class='app-header'><h1>ðŸ“° Haber Ã–zetleyici</h1></div>", unsafe_allow_html=True)
    
    st.markdown("<div class='category-selector'>", unsafe_allow_html=True)
    cols = st.columns(len(CATEGORIES))
    for i, category in enumerate(CATEGORIES.keys()):
        with cols[i]:
            if st.button(
                category, 
                key=f"cat_{category}", 
                use_container_width=True,
                type="primary" if st.session_state.selected_category == category else "secondary"
            ):
                change_category(category)
    st.markdown("</div>", unsafe_allow_html=True)
    
    st.markdown(f"<h2>ðŸ“Œ {st.session_state.selected_category} Haberleri</h2>", unsafe_allow_html=True)
    
    if not st.session_state.news_data:
        with st.spinner(f"{st.session_state.selected_category} haberleri yÃ¼kleniyor..."):
            st.session_state.news_data = fetch_news_list(st.session_state.selected_category)
    
    if st.button("ðŸ§  TÃ¼m Haberleri Ã–zetle", type="primary"):
        summarize_all_news()
    
    if st.session_state.all_summarized:
        st.markdown("<div class='summary-header'><h2>ðŸ“‹ TÃ¼m Haberler - Ã–zet</h2></div>", unsafe_allow_html=True)
        
        for i, news in enumerate(st.session_state.news_data):
            if news["ai_summary"]:
                st.markdown(f"""
                <div class='summary-item'>
                    <strong>{i+1}. {news['title']}</strong><br>
                    {news['ai_summary']}
                </div>
                """, unsafe_allow_html=True)
    
    if st.session_state.news_data:
        cols_per_row = 3
        for i in range(0, len(st.session_state.news_data), cols_per_row):
            cols = st.columns(cols_per_row)
            for j in range(cols_per_row):
                idx = i + j
                if idx < len(st.session_state.news_data):
                    news = st.session_state.news_data[idx]
                    with cols[j]:
                        st.markdown(f"""
                        <div class='news-card'>
                            <img src="{news['image'] if news['image'] else 'https://via.placeholder.com/300x200'}" class='news-image'>
                            <div class='news-title'>{news['title']}</div>
                            <div class='news-source'>{news['image']}</div>
                            <div class='news-source'>{news['source']}</div>
                            <div class='news-date'>{news['date']}</div>
                            <div class='news-summary'>{news['summary']}</div>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.markdown(f"<a href='{news['url']}' target='_blank'><button style='width:100%;'>Habere Git</button></a>", unsafe_allow_html=True)
                        with col2:
                            if news["id"] in st.session_state.summarized_news:
                                if st.button("Ã–zeti GÃ¶ster", key=f"show_{news['id']}"):
                                    st.info(news["ai_summary"])
                            else:
                                if st.button("Ã–zetle", key=f"sum_{news['id']}"):
                                    summarize_and_save(news["id"])
    else:
        st.info(f"HenÃ¼z {st.session_state.selected_category} kategorisinde haber bulunamadÄ±.")

if __name__ == "__main__":
    main()
